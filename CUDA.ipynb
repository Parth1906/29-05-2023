{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b1tej7vGZy4",
        "outputId": "cdb97f7b-ee6d-4d91-8f67-b79e4d32d04c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwjTQ2ZuHuUq",
        "outputId": "9f6defbf-c5c5-487b-e49b-3bff68a26d4e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-sxpz4noh\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-sxpz4noh\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4287 sha256=12d9fb1fc4927703229552f917dc0366b42b79c08e7239bd7c1f5175e6b32ed0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-n2sohj1h/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vector Addition"
      ],
      "metadata": {
        "id": "oULFIboBHlt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jU9pQ13qHryW",
        "outputId": "91483edf-1537-45f8-e3dd-ff8fa2950d9d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "\n",
        "#define N 5// Size of the vectors\n",
        "\n",
        "// CUDA kernel to add two vectors\n",
        "__global__\n",
        "void vectorAdd(int *a, int *b, int *c)\n",
        "{\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (tid < N)\n",
        "    {\n",
        "        c[tid] = a[tid] + b[tid];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int *a, *b, *c; // Host vectors\n",
        "    int *d_a, *d_b, *d_c; // Device vectors\n",
        "\n",
        "    // Allocate memory for the host vectors\n",
        "    a = (int*)malloc(N * sizeof(int));\n",
        "    b = (int*)malloc(N * sizeof(int));\n",
        "    c = (int*)malloc(N * sizeof(int));\n",
        "\n",
        "    // Initialize the host vectors\n",
        "    for (int i = 0; i < N; i++)\n",
        "    {\n",
        "        a[i] = i;\n",
        "        b[i] = 2 * i;\n",
        "    }\n",
        "\n",
        "    // Allocate memory for the device vectors\n",
        "    cudaMalloc(&d_a, N * sizeof(int));\n",
        "    cudaMalloc(&d_b, N * sizeof(int));\n",
        "    cudaMalloc(&d_c, N * sizeof(int));\n",
        "\n",
        "    // Copy the host vectors to device\n",
        "    cudaMemcpy(d_a, a, N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, b, N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Perform the vector addition on the GPU\n",
        "    int blockSize = 256;\n",
        "    int gridSize = (N + blockSize - 1) / blockSize;\n",
        "    vectorAdd<<<gridSize, blockSize>>>(d_a, d_b, d_c);\n",
        "\n",
        "    // Copy the result back to host\n",
        "    cudaMemcpy(c, d_c, N * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Display the vectors and result\n",
        "    printf(\"Vector A:\\n\");\n",
        "    for (int i = 0; i < N; i++)\n",
        "    {\n",
        "        printf(\"%d \", a[i]);\n",
        "    }\n",
        "    printf(\"\\n\\n\");\n",
        "\n",
        "    printf(\"Vector B:\\n\");\n",
        "    for (int i = 0; i < N; i++)\n",
        "    {\n",
        "        printf(\"%d \", b[i]);\n",
        "    }\n",
        "    printf(\"\\n\\n\");\n",
        "\n",
        "    printf(\"Resultant Vector C:\\n\");\n",
        "    for (int i = 0; i < N; i++)\n",
        "    {\n",
        "        printf(\"%d \", c[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    // Cleanup\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(c);\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-B7wwF9gJN7i",
        "outputId": "167576a2-a595-4fc2-9add-4ddc8c45d4f0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector A:\n",
            "0 1 2 3 4 \n",
            "\n",
            "Vector B:\n",
            "0 2 4 6 8 \n",
            "\n",
            "Resultant Vector C:\n",
            "0 3 6 9 12 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matrix Multiplication"
      ],
      "metadata": {
        "id": "XcehDc9OLB3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "#include <cuda.h>\n",
        "\n",
        "// Matrix multiplication kernel\n",
        "__global__ void matrixMultiplication(float* A, float* B, float* C, int N) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < N && col < N) {\n",
        "        float sum = 0.0f;\n",
        "        for (int i = 0; i < N; ++i) {\n",
        "            sum += A[row * N + i] * B[i * N + col];\n",
        "        }\n",
        "        C[row * N + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int N = 2; // Matrix size\n",
        "    int size = N * N * sizeof(float);\n",
        "    dim3 blockSize(16, 16); // Threads per block\n",
        "    dim3 gridSize((N + blockSize.x - 1) / blockSize.x, (N + blockSize.y - 1) / blockSize.y); // Blocks per grid\n",
        "\n",
        "    // Allocate memory on the host\n",
        "    float* h_A = (float*)malloc(size);\n",
        "    float* h_B = (float*)malloc(size);\n",
        "    float* h_C = (float*)malloc(size);\n",
        "\n",
        "    // Initialize input matrices\n",
        "    for (int i = 0; i < N * N; ++i) {\n",
        "        h_A[i] = i;\n",
        "        h_B[i] = i;\n",
        "    }\n",
        "\n",
        "    // Print input matrices\n",
        "    std::cout << \"Matrix A:\" << std::endl;\n",
        "    for (int i = 0; i < N * N; ++i) {\n",
        "        std::cout << h_A[i] << \" \";\n",
        "        if ((i + 1) % N == 0) {\n",
        "            std::cout << std::endl;\n",
        "        }\n",
        "    }\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    std::cout << \"Matrix B:\" << std::endl;\n",
        "    for (int i = 0; i < N * N; ++i) {\n",
        "        std::cout << h_B[i] << \" \";\n",
        "        if ((i + 1) % N == 0) {\n",
        "            std::cout << std::endl;\n",
        "        }\n",
        "    }\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    // Allocate memory on the device\n",
        "    float* d_A, * d_B, * d_C;\n",
        "    cudaMalloc(&d_A, size);\n",
        "    cudaMalloc(&d_B, size);\n",
        "    cudaMalloc(&d_C, size);\n",
        "\n",
        "    // Copy input matrices from host to device\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch the matrix multiplication kernel\n",
        "    matrixMultiplication<<<gridSize, blockSize>>>(d_A, d_B, d_C, N);\n",
        "\n",
        "    // Copy the result matrix from device to host\n",
        "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print the result matrix\n",
        "    std::cout << \"Result Matrix C:\" << std::endl;\n",
        "    for (int i = 0; i < N * N; ++i) {\n",
        "        std::cout << h_C[i] << \" \";\n",
        "        if ((i + 1) % N == 0) {\n",
        "            std::cout << std::endl;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    // Free host memory\n",
        "    free(h_A);\n",
        "   \n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vSDzYNEKBfa",
        "outputId": "7e75e50a-b800-434c-bb46-99a5394569e0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix A:\n",
            "0 1 \n",
            "2 3 \n",
            "\n",
            "Matrix B:\n",
            "0 1 \n",
            "2 3 \n",
            "\n",
            "Result Matrix C:\n",
            "2 3 \n",
            "6 11 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GH8tRlTgLJ16"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}